{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88105eff",
   "metadata": {},
   "source": [
    "### 목표\n",
    "- 폐암환자의 생존을 예측하는 모델을 만들어보자!\n",
    "- 신경망을 활용하여 2진분류 문데를 해결해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b057bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0cfc086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>369</td>\n",
       "      <td>6</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>406</td>\n",
       "      <td>6</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>447</td>\n",
       "      <td>8</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
       "0    293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   \n",
       "1      1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   \n",
       "2      8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   \n",
       "3     14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   \n",
       "4     17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   \n",
       "..   ...  ..   ...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "465   98   6  3.04  2.40   2   0   0   0   1   0  11   0   0   0   1   0  76   \n",
       "466  369   6  3.88  2.72   1   0   0   0   1   0  12   0   0   0   1   0  77   \n",
       "467  406   6  5.36  3.96   1   0   0   0   1   0  12   0   0   0   0   0  62   \n",
       "468   25   8  4.32  3.20   0   0   0   0   0   0  11   0   0   0   0   0  58   \n",
       "469  447   8  5.20  4.10   0   0   0   0   0   0  12   0   0   0   0   0  49   \n",
       "\n",
       "     17  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     0  \n",
       "..   ..  \n",
       "465   0  \n",
       "466   0  \n",
       "467   0  \n",
       "468   1  \n",
       "469   0  \n",
       "\n",
       "[470 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# header : 데이터프레임에서 컬럼명을 설정해주는 함수(None : 인덱스 번호로 출력)\n",
    "data = pd.read_csv(\"data/ThoraricSurgery.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6584720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제, 정답 직접 분리시켜보세요~!\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c15529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 평가 데이터 분리시켜보세요~!\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0adf82c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 17)\n",
      "(118, 17)\n",
      "(352,)\n",
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041646f",
   "metadata": {},
   "source": [
    "### keras를 활용하여 딥러닝 신경망을 구성해보자!\n",
    "- 1. 신경망 구조 설계\n",
    "- 2. 학습/평가방법 설정\n",
    "- 3. 학습+시각화\n",
    "- 4. 모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d4f1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f670cf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                360       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 631\n",
      "Trainable params: 631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 신경망 구조 설계\n",
    "model = Sequential()\n",
    "\n",
    "# 입력층 + 하나의 중간층\n",
    "# input_dim : 입력되는 데이터의 특성 개수\n",
    "# activation : 활성화 함수 설정 명령(들어온 자극(데이터)에 대한 응답여부를 결정)\n",
    "model.add(Dense(20, input_dim=17, activation='sigmoid'))\n",
    "\n",
    "# 중간층(은닉층)\n",
    "model.add(Dense(10, activation='sigmoid'))    # 하나의 층\n",
    "model.add(Dense(5, activation='sigmoid'))     # 하나의 층\n",
    "\n",
    "# 출력층\n",
    "# 출력층 활성화 함수(회귀 : linear(디폴트 값), 2진분류 : sigmoid)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0abad75",
   "metadata": {},
   "source": [
    "### activation(활성화 함수) - 자극에 대한 반응여부를 결정하는 함수\n",
    "- 1. 회귀 : linear(항등함수) -> 신경망에서 도출된 수치값을 그대로 예측에 사용\n",
    "- 2. 분류 : 딥러닝은 선형모델을 기반으로 하고 있기 때문에 도출되는 수치값을 분류에 그대로 사용하기는 힘듦\n",
    "    -  분류 문제는 확률 정보(0~1값)를 가지고 판단하는 것이 정확\n",
    "    - 이진분류 : sigmoid -> 0~1사이 값으로 0 또는 1로 분류(0.5기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "218d245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습/평가방법 설정\n",
    "# binary_crossentropy : 2진분류에 사용하는 손실함수(비용함수)\n",
    "#   -> 오차의 평균을 구하는 것은 mse와 동일하지만 0~1 사이 값으로\n",
    "#      변환 후 평균오차를 구하는 방식\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='SGD',       # 최적화 함수 : 확률적 경사하강법\n",
    "              metrics=['acc']         # metrics : 평가방법을 설정\n",
    "              # 분류 문제이기 때문에 정확도를 평가방법에 추가해 줌\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d350e2e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.5728 - acc: 0.8580\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.5557 - acc: 0.8580\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.5406 - acc: 0.8580\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.5271 - acc: 0.8580\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.5153 - acc: 0.8580\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.5046 - acc: 0.8580\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4952 - acc: 0.8580\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4867 - acc: 0.8580\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4792 - acc: 0.8580\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4724 - acc: 0.8580\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4664 - acc: 0.8580\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4610 - acc: 0.8580\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4561 - acc: 0.8580\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4517 - acc: 0.8580\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4478 - acc: 0.8580\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4442 - acc: 0.8580\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4410 - acc: 0.8580\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 541us/step - loss: 0.4382 - acc: 0.8580\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4355 - acc: 0.8580\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4332 - acc: 0.8580\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4310 - acc: 0.8580\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4291 - acc: 0.8580\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4273 - acc: 0.8580\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4257 - acc: 0.8580\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4242 - acc: 0.8580\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4229 - acc: 0.8580\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4217 - acc: 0.8580\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4206 - acc: 0.8580\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4196 - acc: 0.8580\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4187 - acc: 0.8580\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4178 - acc: 0.8580\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.4171 - acc: 0.8580\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4164 - acc: 0.8580\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4157 - acc: 0.8580\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4151 - acc: 0.8580\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4146 - acc: 0.8580\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.4141 - acc: 0.8580\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4137 - acc: 0.8580\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4132 - acc: 0.8580\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4129 - acc: 0.8580\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4125 - acc: 0.8580\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4122 - acc: 0.8580\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4119 - acc: 0.8580\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4116 - acc: 0.8580\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4114 - acc: 0.8580\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4111 - acc: 0.8580\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4110 - acc: 0.8580\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4108 - acc: 0.8580\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4106 - acc: 0.8580\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4104 - acc: 0.8580\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4103 - acc: 0.8580\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4101 - acc: 0.8580\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 318us/step - loss: 0.4100 - acc: 0.8580\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4098 - acc: 0.8580\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4097 - acc: 0.8580\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4097 - acc: 0.8580\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4095 - acc: 0.8580\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4095 - acc: 0.8580\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4094 - acc: 0.8580\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4093 - acc: 0.8580\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4092 - acc: 0.8580\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4092 - acc: 0.8580\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4091 - acc: 0.8580\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4091 - acc: 0.8580\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4090 - acc: 0.8580\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4090 - acc: 0.8580\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4089 - acc: 0.8580\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4089 - acc: 0.8580\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4088 - acc: 0.8580\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4088 - acc: 0.8580\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4088 - acc: 0.8580\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4088 - acc: 0.8580\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4088 - acc: 0.8580\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4084 - acc: 0.8580\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4084 - acc: 0.8580\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.4084 - acc: 0.8580\n"
     ]
    }
   ],
   "source": [
    "# 3. 학습\n",
    "h = model.fit(X_train, y_train,\n",
    "              epochs=100        # 학습 횟수 설정\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79d28341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. 시각화\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# history : 학습시 출력되는 loss함수 혹은 정확도값을 가져오기 위한 명령\n",
    "plt.plot(h.history['acc'], label='acc')    \n",
    "\n",
    "plt.legend(prop={'size':20}, loc='lower center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ad0c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 499us/step - loss: 0.4563 - acc: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4563225507736206, 0.8305084705352783]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 모델 평가\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
