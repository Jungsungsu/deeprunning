{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a37359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1579d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857f78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ff7b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40fd174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터 원핫인코딩(텐서플로우에서 지원하는 원핫인코딩 기능)\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60d790e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = to_categorical(y)\n",
    "y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4538e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 평가데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=3\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef4b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n",
      "(120, 3)\n",
      "(30, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f418203a",
   "metadata": {},
   "source": [
    "### 신경망 모델링\n",
    "- 1. 신경망 구조설계\n",
    "- 2. 학습/평가 방법 설정\n",
    "- 3. 학습 및 시각화\n",
    "- 4. 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5074d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bc5ff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 2,979\n",
      "Trainable params: 2,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 신경망 구조 설계\n",
    "model = Sequential()\n",
    "\n",
    "# 입력층 + 중간층\n",
    "# relu : 최근에 가장 많이 사용하는 성능 좋은 활성화함수\n",
    "model.add(Dense(64, input_dim=4, activation='relu'))\n",
    "\n",
    "# 중간층(은닉층)\n",
    "model.add(Dense(32, activation='relu'))    # 하나의 층\n",
    "model.add(Dense(16, activation='relu'))    # 하나의 층\n",
    "\n",
    "# 출력층\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef72ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습/평가방법 설정\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',       # 최근에 가장 많이 사용되는 최적화 함수\n",
    "              metrics=['acc']        \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a528031",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 1.3309 - acc: 0.1500\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 738us/step - loss: 1.0939 - acc: 0.6583\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.9469 - acc: 0.6667\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.8493 - acc: 0.6667\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7668 - acc: 0.6667\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.7162 - acc: 0.6667\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6796 - acc: 0.8750\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6448 - acc: 0.9667\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.6152 - acc: 0.9667\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.5883 - acc: 0.9750\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.5634 - acc: 0.9583\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5410 - acc: 0.9333\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5202 - acc: 0.9583\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.5014 - acc: 0.9667\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.4817 - acc: 0.9583\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.4662 - acc: 0.9583\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.4518 - acc: 0.9750\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4343 - acc: 0.9750\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.4214 - acc: 0.9750\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.4084 - acc: 0.9750\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.3952 - acc: 0.9583\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.3814 - acc: 0.9667\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.3692 - acc: 0.9750\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.3562 - acc: 0.9750\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.3436 - acc: 0.9750\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.3322 - acc: 0.9750\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.3195 - acc: 0.9583\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.3133 - acc: 0.9833\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2946 - acc: 0.9750\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2868 - acc: 0.9583\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2754 - acc: 0.9750\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2647 - acc: 0.9750\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2482 - acc: 0.9750\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2353 - acc: 0.9750\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.2290 - acc: 0.9750\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.2215 - acc: 0.9833\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2091 - acc: 0.9750\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1992 - acc: 0.9750\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1910 - acc: 0.9833\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.1827 - acc: 0.9833\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.1829 - acc: 0.9750\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1696 - acc: 0.9833\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1687 - acc: 0.9583\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.1627 - acc: 0.9667\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1590 - acc: 0.9667\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1502 - acc: 0.9833\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1428 - acc: 0.9833\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1458 - acc: 0.9750\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1367 - acc: 0.9750\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1399 - acc: 0.9750\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1289 - acc: 0.9833\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1300 - acc: 0.9833\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1223 - acc: 0.9833\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1217 - acc: 0.9750\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1176 - acc: 0.9750\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.1146 - acc: 0.9833\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1133 - acc: 0.9833\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 495us/step - loss: 0.1096 - acc: 0.9833\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1074 - acc: 0.9833\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1050 - acc: 0.9833\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.1028 - acc: 0.9917\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1040 - acc: 0.9750\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0976 - acc: 0.9833\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1009 - acc: 0.9667\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0963 - acc: 0.9833\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1035 - acc: 0.9750\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0859 - acc: 0.9833\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1071 - acc: 0.9417\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.1003 - acc: 0.9833\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.1018 - acc: 0.9667\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0875 - acc: 0.9917\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0934 - acc: 0.9833\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0859 - acc: 0.9833\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0932 - acc: 0.9750\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0915 - acc: 0.9750\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0863 - acc: 0.9833\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.0837 - acc: 0.9833\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0899 - acc: 0.9833\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0848 - acc: 0.9833\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0821 - acc: 0.9833\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0857 - acc: 0.9833\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0825 - acc: 0.9833\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0885 - acc: 0.9667\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0817 - acc: 0.9833\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0836 - acc: 0.9833\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.0805 - acc: 0.9833\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0778 - acc: 0.9917\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0827 - acc: 0.9917\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0801 - acc: 0.9833\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0776 - acc: 0.9833\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0870 - acc: 0.9750\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0763 - acc: 0.9833\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0807 - acc: 0.9833\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0736 - acc: 0.9833\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0782 - acc: 0.9833\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0741 - acc: 0.9917\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0777 - acc: 0.9833\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0775 - acc: 0.9833\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0714 - acc: 0.9917\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0783 - acc: 0.9833\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0754 - acc: 0.9833\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0776 - acc: 0.9833\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0725 - acc: 0.9833\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0721 - acc: 0.9917\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0742 - acc: 0.9833\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0715 - acc: 0.9833\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0739 - acc: 0.9833\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 743us/step - loss: 0.0711 - acc: 0.9917\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0724 - acc: 0.9833\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0718 - acc: 0.9833\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0714 - acc: 0.9833\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0729 - acc: 0.9917\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0705 - acc: 0.9833\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0730 - acc: 0.9917\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0712 - acc: 0.9833\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0703 - acc: 0.9833\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0738 - acc: 0.9833\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0708 - acc: 0.9917\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0687 - acc: 0.9833\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0689 - acc: 0.9833\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0682 - acc: 0.9833\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0729 - acc: 0.9833\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0720 - acc: 0.9917\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0672 - acc: 0.9833\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0754 - acc: 0.9750\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0784 - acc: 0.9833\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.0720 - acc: 0.9833\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0700 - acc: 0.9833\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0659 - acc: 0.9917\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0722 - acc: 0.9833\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0701 - acc: 0.9833\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0714 - acc: 0.9833\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0677 - acc: 0.9833\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0713 - acc: 0.9833\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0700 - acc: 0.9833\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0697 - acc: 0.9833\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0766 - acc: 0.9750\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0721 - acc: 0.9833\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0747 - acc: 0.9833\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0645 - acc: 0.9833\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0923 - acc: 0.9500\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0650 - acc: 0.9833\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0678 - acc: 0.9833\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0682 - acc: 0.9917\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0723 - acc: 0.9833\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0712 - acc: 0.9833\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0674 - acc: 0.9833\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0691 - acc: 0.9833\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0786 - acc: 0.9750\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0693 - acc: 0.9750\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0667 - acc: 0.9833\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0648 - acc: 0.9833\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0723 - acc: 0.9833\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0643 - acc: 0.9917\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0677 - acc: 0.9833\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0668 - acc: 0.9833\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0702 - acc: 0.9750\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0744 - acc: 0.9750\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.0675 - acc: 0.9833\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0702 - acc: 0.9667\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0682 - acc: 0.9833\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0705 - acc: 0.9833\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0658 - acc: 0.9833\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.0639 - acc: 0.9917\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0666 - acc: 0.9833\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0655 - acc: 0.9833\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0659 - acc: 0.9833\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0655 - acc: 0.9917\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0672 - acc: 0.9833\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0641 - acc: 0.9833\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0640 - acc: 0.9833\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0689 - acc: 0.9833\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 250us/step - loss: 0.0629 - acc: 0.9833\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0640 - acc: 0.9917\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0737 - acc: 0.9833\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0618 - acc: 0.9833\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0708 - acc: 0.9750\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 747us/step - loss: 0.0622 - acc: 0.9833\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0742 - acc: 0.9750\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0683 - acc: 0.9917\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0693 - acc: 0.9833\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0624 - acc: 0.9917\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0675 - acc: 0.9833\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0628 - acc: 0.9917\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0635 - acc: 0.9833\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0643 - acc: 0.9833\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0728 - acc: 0.9750\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 249us/step - loss: 0.0669 - acc: 0.9833\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0644 - acc: 0.9833\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0665 - acc: 0.9917\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0671 - acc: 0.9750\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0731 - acc: 0.9750\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0683 - acc: 0.9833\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0703 - acc: 0.9750\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0736 - acc: 0.9750\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0668 - acc: 0.9833\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0647 - acc: 0.9917\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0628 - acc: 0.9833\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0641 - acc: 0.9833\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0629 - acc: 0.9833\n"
     ]
    }
   ],
   "source": [
    "# 3. 학습\n",
    "h = model.fit(X_train, y_train,\n",
    "              epochs=200        # 학습 횟수 설정\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e7435a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. 시각화\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(h.history['acc'], label='acc')    \n",
    "\n",
    "plt.legend(prop={'size':80}, loc='lower center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be834d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.0484 - acc: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04843408614397049, 0.9666666388511658]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 모델 평가\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6392bc0",
   "metadata": {},
   "source": [
    "### 1. 회귀\n",
    "- loss = mse(평균제곱오차)\n",
    "- 출력층 뉴런의 개수 : 1\n",
    "- 출력층 활성화 함수 : linear(항등함수) → 디폴트 값\n",
    "\n",
    "### 2. 2진분류\n",
    "- loss : binary_crossentropy\n",
    "- 출력층 뉴런의 개수 : 1\n",
    "- 출력층 활성화 함수 : sigmoid\n",
    "\n",
    "### 3. 다중분류\n",
    "- loss : categorical_crossentropy\n",
    "- 출력층 뉴런의 개수 : 정답의 개수(원핫인코딩 된 레이블의 개수)\n",
    "- 출력층 활성화 함수 : softmax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
